{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate inter-relater reliability for glosses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(df1, df2, col_ls):\n",
    "    \n",
    "    \"\"\"\n",
    "    Finds the correct participant + generation subset\n",
    "    in df2 based on the subset found in df1.\n",
    "    \n",
    "    Formats subset to contain cols in col_ls and sorts by\n",
    "    participant and target.\n",
    "    \n",
    "    This produces a df based on df2 that is in the same order as df1.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    pieces = []\n",
    "\n",
    "    # get unique particpiant and generation combinations\n",
    "    unique_ps = df1[['participant', 'generation']].drop_duplicates().reset_index()\n",
    "    \n",
    "    # for each row \n",
    "    # get subset of that participant and gen from df2\n",
    "    for ind, row in unique_ps.iterrows():\n",
    "        \n",
    "        p = unique_ps.loc[ind, \"participant\"]\n",
    "        g = unique_ps.loc[ind, 'generation']\n",
    "        \n",
    "        subset = df2[(df2.participant==p) \n",
    "                    & (df2.generation==g)]\n",
    "        \n",
    "        pieces.append(subset)\n",
    "        \n",
    "    # concatenate all subsets\n",
    "    full_subset = pd.concat(pieces, ignore_index=True)\n",
    "    \n",
    "    # get only cols in col list and sort\n",
    "    full_subset = full_subset[col_ls].sort_values(by=['participant',\n",
    "                                                     'target']).reset_index(drop=True)\n",
    "    \n",
    "    return full_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_marker_pres(df1, df2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get % agreement for marker presence.\n",
    "    \n",
    "    Compares marker presence along rows of 2 dfs.\n",
    "    If same, increases count, then finds % of values\n",
    "    that are the same.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for ind, row in df1.iterrows():\n",
    "        \n",
    "        mPres1 = df1.loc[ind, 'markerPres']\n",
    "        mPres2 = df2.loc[ind, 'markerPres']\n",
    "        \n",
    "        if mPres1 == mPres2:\n",
    "            \n",
    "            count +=1\n",
    "            \n",
    "    return (float(count)/len(df1)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same shape list function as used for entropy\n",
    "# used to get list of gesture shapes for a given meaning\n",
    "\n",
    "def shape_list(alist,reg):\n",
    "    #join list of code\n",
    "    allcode=(',').join(alist)\n",
    "    #search for gesture shapes (expressions starting with 1h or 2h)\n",
    "    regex=re.compile(reg)\n",
    "    setlist=re.findall(regex,allcode)\n",
    "    #return the list of shapes and the set of different shapes\n",
    "    return setlist, set(setlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find jaccard similarity for two sets\n",
    "\n",
    "def jaccard_index(setA,setB):\n",
    "    A=len(list(setA))\n",
    "    B=len(list(setB))\n",
    "    AB=len(list(setA.intersection(setB)))\n",
    "    denom=float(A+B-AB)\n",
    "    if denom==0:\n",
    "        j_ind=float('nan')\n",
    "    else:\n",
    "        j_ind=AB/denom\n",
    "    return j_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_targets(df):\n",
    "    \n",
    "    cols = ['target', 'genA', 'codeA', 'genB', 'codeB']\n",
    "    \n",
    "    byTarget_df = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    for t in df.target.unique():\n",
    "        \n",
    "        t_subset = df[df.target==t].reset_index()\n",
    "        \n",
    "        for p in combinations(range(len(t_subset)), 2):\n",
    "            \n",
    "            row_ls = [t]\n",
    "            \n",
    "            for i in p:\n",
    "                \n",
    "                i_info = list(t_subset.loc[i, ['participant', 'code_string']].values)\n",
    "                \n",
    "                row_ls += i_info\n",
    "                \n",
    "            row_dict = dict(zip(cols, row_ls))\n",
    "            \n",
    "            byTarget_df = byTarget_df.append(row_dict, ignore_index=True)\n",
    "                \n",
    "    return byTarget_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jaccard(df):\n",
    "    \n",
    "    for ind, row in df.iterrows():\n",
    "        \n",
    "        code_sets = []\n",
    "        \n",
    "        for c in ['A', 'B']:\n",
    "            \n",
    "            code = df.loc[ind, 'code' + c]\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                code_set = set(re.findall(reg, code))\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                code_set = set([])\n",
    "                \n",
    "            code_sets.append(code_set)\n",
    "        \n",
    "        j_ind = jaccard_index(code_sets[0], code_sets[1])\n",
    "        \n",
    "        df.loc[ind, 'jaccardIndex'] = j_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_df(df_list):\n",
    "    \n",
    "    pieces = []\n",
    "    \n",
    "    for df_ind in range(len(df_list)):\n",
    "        \n",
    "        df = df_list[df_ind]\n",
    "        \n",
    "        target_gb = df[['target', 'jaccardIndex']].groupby('target').agg(np.mean).reset_index()\n",
    "        \n",
    "        target_gb = target_gb.rename(columns={'jaccardIndex': 'jaccard' + str(df_ind + 1)})\n",
    "        \n",
    "        pieces.append(target_gb)\n",
    "        \n",
    "    comp_df = pd.concat(pieces, axis=1, copy=False)\n",
    "    \n",
    "    return comp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jaccard_comparison(df1, df2):\n",
    "    \n",
    "    target_dfs = []\n",
    "    \n",
    "    for df in [df1, df2]:\n",
    "        \n",
    "        target_df = compare_targets(df)\n",
    "        \n",
    "        add_jaccard(target_df)\n",
    "        \n",
    "        target_dfs.append(target_df)\n",
    "        \n",
    "    full_comp_df = comparison_df(target_dfs)\n",
    "    \n",
    "    return full_comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression to extract shape codes\n",
    "reg = r'1h.*?\\b|2h.*?\\b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second coder files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed data\n",
    "c2seed = pd.read_csv('../data_files/seed_second_coder.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 1\n",
    "c2ex1 = pd.read_csv('../data_files/ex1_second_coder.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get columns to use throughout analysis\n",
    "cols = c2ex1.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 2\n",
    "c2ex2int = pd.read_csv('../data_files/ex2_int_only_second_coder.csv')\n",
    "c2ex2trans = pd.read_csv('../data_files/ex2_trans_only_second_coder.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 3\n",
    "\n",
    "c2ex3int = pd.read_csv('../data_files/ex3_int_only_second_coder.csv')\n",
    "c2ex3transint = pd.read_csv('../data_files/ex3_transint_second_coder.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First coder files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 1\n",
    "c1ex1 = pd.read_csv('../data_files/ex1.csv')\n",
    "# experiment 2\n",
    "c1ex2 = pd.read_csv('../data_files/ex2.csv')\n",
    "# experiment 3\n",
    "c1ex3 = pd.read_csv('../data_files/ex3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2seed['generation'] = 0\n",
    "c2seed['trial'] = np.nan\n",
    "\n",
    "c2seed = c2seed[cols].sort_values(by=['participant']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1seed = c1ex1[c1ex1.participant.isin(c2seed.participant.unique())].drop_duplicates(subset=\n",
    "                                                                                    ['participant'])\n",
    "\n",
    "c1seed = c1seed[cols].sort_values(by='participant').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format 2nd coder's df\n",
    "c2ex1 = c2ex1[cols].sort_values(by=['participant', \n",
    "                                    'target']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get subset for c1\n",
    "c1ex1_subset = get_subset(c2ex1, c1ex1, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c1ex1_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add seeds\n",
    "c2ex1 = pd.concat([c2seed, c2ex1], ignore_index=True)\n",
    "c1ex1_subset = pd.concat([c1seed, c1ex1_subset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marker presence agreement: 93.700000 %\n"
     ]
    }
   ],
   "source": [
    "# percent agreement for marker presence\n",
    "mp_ex1 = compare_marker_pres(c1ex1_subset, c2ex1)\n",
    "\n",
    "print \"Marker presence agreement: %f %%\" %round(mp_ex1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86825251601097897"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(c1ex1_subset.markerPres, c2ex1.markerPres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1_comp = create_jaccard_comparison(c1ex1_subset, c2ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.72584856396866848, pvalue=5.9542263133494567e-05)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(ex1_comp.jaccard1, ex1_comp.jaccard2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2ex2 = pd.concat([c2ex2int, c2ex2trans], ignore_index=True)\n",
    "c2ex2 = c2ex2[cols].sort_values(by=['participant', 'target']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1ex2_subset = get_subset(c2ex2, c1ex2, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marker presence agreement: 92.900000 %\n"
     ]
    }
   ],
   "source": [
    "mp_ex2 = compare_marker_pres(c1ex2_subset, c2ex2)\n",
    "\n",
    "print \"Marker presence agreement: %f %%\" %round(mp_ex2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84643179765130983"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(c1ex2_subset.markerPres, c2ex2.markerPres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2_comp = create_jaccard_comparison(c1ex2_subset, c2ex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.83478260869565213, pvalue=3.9327462000564876e-07)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(ex2_comp.jaccard1, ex2_comp.jaccard2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2ex3 = pd.concat([c2ex3int, c2ex3transint], ignore_index=True)\n",
    "\n",
    "c2ex3 = c2ex3[cols].sort_values(by=['participant', 'target']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1ex3_subset = get_subset(c2ex3, c1ex3, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.25"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_marker_pres(c1ex3_subset, c2ex3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81878325902488136"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(c1ex3_subset.markerPres, c2ex3.markerPres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex3_comp = create_jaccard_comparison(c1ex3_subset, c2ex3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.9086956521739129, pvalue=8.263058014053956e-10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(ex3_comp.jaccard1, ex3_comp.jaccard2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
